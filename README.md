
# Gutenberg Novel Analysis

*In this project, we performed text analysis on two of our chosen books from Gutenberg using Natural Language Processing Techniques*

![Books Used](https://user-images.githubusercontent.com/65908705/107999517-8dc02e00-700d-11eb-961b-8e64e012d5db.png)

**GOALS**

1.  Import the text from two books, let's call it as T1 and T2.
    
2.  Perform simple text pre-processing steps and tokenize the text T1 and T2.
    
3.  Analyze the frequency distribution of tokens in T1 and T2 separately.
    
4.  Create a Word Cloud of T1 and T2 using the token that you have got.
    
5.  Remove the stopwords from T1 and T2 and then again create a word cloud.
    
6.  Compare with word clouds before the removal of stopwords.
    
7.  Evaluate the relationship between the word length and frequency for both T1 and T2.
    
8.  Do PoS Tagging for both T1 and T2 using anyone of the four tagset studied in the class and Get the distribution of various tags


**SPECIFICATIONS**

*Python Libraries used in this project :*

***urllib*** - Used to fetch text data from Gutenberg URLs  
***nltk*** - Used for Tokenizing, Lemmatization and Removing Stopwords  
***re*** - Used to remove URLs and Decontract Contractions in English Language 
***wordcloud*** - Used to create WordClouds from Tokenized Data  
***inflect*** - Used to replace numbers with words  
***matplotlib*** - Used to Visualize our text data
